{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests  \n",
    "import math  \n",
    "import pandas as pd  \n",
    "import time\n",
    "import urllib\n",
    "import urllib.request\n",
    "from bs4 import BeautifulSoup as Bs\n",
    "import random\n",
    "import re\n",
    "random.seed(36)\n",
    "\n",
    "def get_proxy():\n",
    "    user_agent = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.87 Safari/537.36'\n",
    "    headers = {'User-Agent': user_agent}\n",
    "    req = urllib.request.Request('https://free-proxy-list.net/', headers=headers)\n",
    "\n",
    "    page = urllib.request.urlopen(req).read().decode('utf-8')\n",
    "    soup = Bs(page, 'html.parser')\n",
    "\n",
    "    ip_add = []\n",
    "    ds = []\n",
    "    divs = soup.find_all('td', attrs={'class':None})\n",
    "    for i, tag in enumerate(divs):\n",
    "        if i%4 == 0:\n",
    "            ip_add.append(ds)\n",
    "            ds = []\n",
    "        ds.append(tag.text)\n",
    "    \n",
    "    ip = pd.DataFrame(data = ip_add, columns = ['ip','port','Country','type'])\n",
    "\n",
    "    ran = random.randint(0,100)\n",
    "    http = 'http://'+ip.iloc[ran][0]+':'+ip.iloc[ran][1]\n",
    "    https = 'https://'+ip.iloc[ran][0]+':'+ip.iloc[ran][1]\n",
    "    \n",
    "    return http, https\n",
    "\n",
    "def get_json(url,num,pos):  \n",
    "    '''''从网页获取JSON,使用POST请求,加上头部信息''' \n",
    "    http, https = get_proxy()\n",
    "\n",
    "    proxies = {\n",
    "        'http': http,\n",
    "        'https': https,\n",
    "    }\n",
    "\n",
    "    # Create the session and set the proxies.\n",
    "    s = requests.Session()\n",
    "    s.proxies = proxies\n",
    "\n",
    "    # Make the HTTP request through the session.\n",
    "    #r = s.get('http://www.showmemyip.com/')\n",
    "    '''''从网页获取JSON,使用POST请求,加上头部信息''' \n",
    "    user_agents=['Mozilla/5.0 (Windows NT 6.1; WOW64; rv:23.0) Gecko/20130406 Firefox/23.0',\n",
    "                   'Mozilla/5.0 (Windows NT 6.1; WOW64; rv:18.0) Gecko/20100101 Firefox/18.0',\n",
    "                   'Mozilla/5.0 (Windows; U; Windows NT 6.1; en-US) AppleWebKit/533+ \\(KHTML, like Gecko) Element Browser 5.0',\n",
    "                   'IBM WebExplorer /v0.94', 'Galaxy/1.0 [en] (Mac OS X 10.5.6; U; en)',\n",
    "                   'Mozilla/5.0 (compatible; MSIE 10.0; Windows NT 6.1; WOW64; Trident/6.0)',\n",
    "                   'Opera/9.80 (Windows NT 6.0) Presto/2.12.388 Version/12.14',\n",
    "                   'Mozilla/5.0 (iPad; CPU OS 6_0 like Mac OS X) AppleWebKit/536.26 (KHTML, like Gecko) \\Version/6.0 Mobile/10A5355d Safari/8536.25',\n",
    "                   'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) \\Chrome/28.0.1468.0 Safari/537.36',\n",
    "                   'Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.0; Trident/5.0; TheWorld)']\n",
    "    index=random.randint(0, 9)\n",
    "    user_agent=user_agents[index]\n",
    "    my_headers = {  \n",
    "            'User-Agent':user_agent,  \n",
    "            'Host':'www.lagou.com',  \n",
    "            'Referer':'https://www.lagou.com/jobs/list_%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90?labelWords=&fromSearch=true&suginput=',  \n",
    "            'X-Anit-Forge-Code':'0',  \n",
    "            'X-Anit-Forge-Token': 'None',  \n",
    "            'X-Requested-With':'XMLHttpRequest'  \n",
    "            }  \n",
    "\n",
    "    my_data = {  \n",
    "            'first': 'true',  \n",
    "            'pn':num,  \n",
    "            'kd':pos}  \n",
    "\n",
    "    res = s.post(url, headers = my_headers, data = my_data)  \n",
    "    # Check if the proxy was indeed used (the text should contain the proxy IP).\n",
    "    res.raise_for_status()  \n",
    "    res.encoding = 'utf-8'  \n",
    "    # 得到包含职位信息的字典  \n",
    "    page = res.json()  \n",
    "    return page\n",
    "\n",
    "\n",
    "def get_page_num(count):  \n",
    "    '''''计算要抓取的页数'''  \n",
    "    # 每页15个职位,向上取整  \n",
    "    res = math.ceil(count/15)  \n",
    "    # 拉勾网最多显示30页结果  \n",
    "    if res > 30:  \n",
    "        return 30  \n",
    "    else:  \n",
    "        return res  \n",
    "\n",
    "def get_page_info(jobs_list):  \n",
    "    '''''对一个网页的职位信息进行解析,返回列表'''  \n",
    "    page_info_list = []  \n",
    "    for n, i in enumerate(jobs_list): \n",
    "        print('现在进行到第{}个；'.format(n))\n",
    "        job_info = []  \n",
    "        job_info.append(i['companyFullName'])  \n",
    "        job_info.append(i['companyShortName'])  \n",
    "        job_info.append(i['companySize'])  \n",
    "        job_info.append(i['financeStage'])  \n",
    "        job_info.append(i['district'])  \n",
    "        job_info.append(i['positionName'])  \n",
    "        job_info.append(i['workYear'])  \n",
    "        job_info.append(i['education'])  \n",
    "        job_info.append(i['salary'])  \n",
    "        job_info.append(i['positionAdvantage'])  \n",
    "        job_info.append(i['positionId'])\n",
    "        \n",
    "        url = 'https://www.lagou.com/jobs/'+ str(i['positionId']) +'.html'\n",
    "        user_agents=['Mozilla/5.0 (Windows NT 6.1; WOW64; rv:23.0) Gecko/20130406 Firefox/23.0',\n",
    "                   'Mozilla/5.0 (Windows NT 6.1; WOW64; rv:18.0) Gecko/20100101 Firefox/18.0',\n",
    "                   'Mozilla/5.0 (Windows; U; Windows NT 6.1; en-US) AppleWebKit/533+ \\(KHTML, like Gecko) Element Browser 5.0',\n",
    "                   'IBM WebExplorer /v0.94', 'Galaxy/1.0 [en] (Mac OS X 10.5.6; U; en)',\n",
    "                   'Mozilla/5.0 (compatible; MSIE 10.0; Windows NT 6.1; WOW64; Trident/6.0)',\n",
    "                   'Opera/9.80 (Windows NT 6.0) Presto/2.12.388 Version/12.14',\n",
    "                   'Mozilla/5.0 (iPad; CPU OS 6_0 like Mac OS X) AppleWebKit/536.26 (KHTML, like Gecko) \\Version/6.0 Mobile/10A5355d Safari/8536.25',\n",
    "                   'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) \\Chrome/28.0.1468.0 Safari/537.36',\n",
    "                   'Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.0; Trident/5.0; TheWorld)']\n",
    "        index=random.randint(0, 9)\n",
    "        user_agent=user_agents[index]\n",
    "        headers = {  \n",
    "                'User-Agent':user_agent,  \n",
    "                'Host':'www.lagou.com',  \n",
    "                'Referer':'https://www.lagou.com/jobs/list_%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90?labelWords=&fromSearch=true&suginput=',  \n",
    "                'X-Anit-Forge-Code':'0',  \n",
    "                'X-Anit-Forge-Token': 'None',  \n",
    "                'X-Requested-With':'XMLHttpRequest'  \n",
    "                }  \n",
    "        http, https = get_proxy()\n",
    "        proxies = {\n",
    "            'http': http,\n",
    "            'https': https,\n",
    "        }\n",
    "        #data = urllib.parse.urlencode(dict).encode('utf-8')\n",
    "        #data参数如果要传必须传bytes（字节流）类型的，如果是一个字典，先用urllib.parse.urlencode()编码。\n",
    "        time_sleep = random.randint(10, 30)\n",
    "        time.sleep(time_sleep)  \n",
    "        try:\n",
    "            s = requests.Session()\n",
    "            s.proxies = proxies\n",
    "            res = s.post(url, headers = headers)  \n",
    "            # Check if the proxy was indeed used (the text should contain the proxy IP).\n",
    "            res.raise_for_status()  \n",
    "            res.encoding = 'utf-8' \n",
    "            soup = Bs(res.content, 'html.parser')\n",
    "            content = soup.find('dd', class_='job_bt').get_text()\n",
    "            job_info.append(content)\n",
    "        except:\n",
    "            print('访问网页失败！')\n",
    "        finally:    \n",
    "            page_info_list.append(job_info)  \n",
    "    return page_info_list  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "请输入你想查阅的职位名称：AI算法工程师\n",
      "职位总数:29082,页数:30\n"
     ]
    }
   ],
   "source": [
    "random.seed(36)\n",
    "\n",
    "url = 'https://www.lagou.com/jobs/positionAjax.json?px=new&needAddtionalResult=false'\n",
    "#url = 'https://www.lagou.com/jobs/positionAjax.json?city=%E6%B7%B1%E5%9C%B3&needAddtionalResult=false'  \n",
    "# 先设定页数为1,获取总的职位数  \n",
    "pos = input('请输入你想查阅的职位名称：')\n",
    "page_1 = get_json(url,1,pos)  \n",
    "total_count = page_1['content']['positionResult']['totalCount']  \n",
    "num = get_page_num(total_count)  \n",
    "total_info = []  \n",
    "time_sleep = random.randint(10, 30)\n",
    "time.sleep(time_sleep)  \n",
    "print('职位总数:{},页数:{}'.format(total_count,num))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "现在进行到第0个；\n",
      "现在进行到第1个；\n",
      "现在进行到第2个；\n",
      "现在进行到第3个；\n",
      "现在进行到第4个；\n",
      "现在进行到第5个；\n",
      "现在进行到第6个；\n",
      "现在进行到第7个；\n",
      "现在进行到第8个；\n"
     ]
    }
   ],
   "source": [
    "#total_info = []  \n",
    "for n in range(0,num+1):  \n",
    "    # 对每个网页读取JSON, 获取每页数据  \n",
    "    page = get_json(url,n,pos)  \n",
    "    jobs_list = page['content']['positionResult']['result']  \n",
    "    page_info = get_page_info(jobs_list)  \n",
    "    total_info += page_info  \n",
    "    print('已经抓取第{}页, 职位总数:{}'.format(n, len(total_info)))  \n",
    "    # 每次抓取完成后,暂停一会,防止被服务器拉黑  \n",
    "    time_sleep = random.randint(10, 30)\n",
    "    time.sleep(time_sleep)  \n",
    "#将总数据转化为data frame再输出  \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data = total_info,columns = ['公司全名','公司简称','公司规模','融资阶段','区域','职位名称','工作经验','学历要求','工资','职位福利','职位id','职位描述'])   \n",
    "df.to_csv('lagou_jobs_{}.csv'.format(n),index = False)  \n",
    "print('已保存为csv文件.') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
